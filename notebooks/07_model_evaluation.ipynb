{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "## Best ML vs Best DL\n",
        "### Evaluation & Visualization\n",
        "### Models\n",
        " - Best ML: LightGBM\n",
        " - Best DL: Seq2Seq"
      ],
      "metadata": {
        "id": "5jFf8wWbZONs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone GitHub Repository\n",
        "!git clone https://github.com/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform.git\n",
        ""
      ],
      "metadata": {
        "id": "owqiMcfJZscN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os, gc, json, joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "otHRFH0cYKGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Project Root\n",
        "os.chdir('/content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform')\n",
        "print(\"Current Directory: \", os.getcwd())"
      ],
      "metadata": {
        "id": "PUdZ1LtVbiyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = Path('models')\n",
        "REPORT_PATH = Path('data/reports')\n",
        "REPORT_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "-YLZH73UaHwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Original Data\n",
        "train = pd.read_parquet(\"data/features/train_features.parquet\")\n",
        "\n",
        "train[\"date\"] = pd.to_datetime(train[\"date\"])\n",
        "train = train.sort_values([\"store_nbr\", \"family\", \"date\"]).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "ftwp1QFckVY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop lag NaNs\n",
        "lag_cols = [c for c in train.columns if \"lag\" in c or \"roll\" in c]\n",
        "train = train.dropna(subset=lag_cols).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "rDRmF_5a5jqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory Optimization (reduce memory usage)\n",
        "def reduce_mem_usage(df, ):\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == \"float64\":\n",
        "      df[col] = df[col].astype(\"float32\")\n",
        "    elif df[col].dtype == \"int64\":\n",
        "      df[col] = df[col].astype(\"int32\")\n",
        "  return df\n",
        "\n",
        "train = reduce_mem_usage(train)\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "EbL5bgO3mSdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on ML(LightGBM) Model"
      ],
      "metadata": {
        "id": "5loQIsajGAUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate Features\n",
        "DROP_COLS = [\"id\", \"date\", \"sales\", \"sales_log\"]\n",
        "TARGET = \"sales_log\"\n",
        "\n",
        "FEATURES = [c for c in train.columns if c not in DROP_COLS]\n",
        "\n",
        "X_full = train[FEATURES]\n",
        "y_full = train[TARGET]\n"
      ],
      "metadata": {
        "id": "t5xsAdZj-wWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical Features\n",
        "CAT_COLS = [\n",
        "    'family',\n",
        "    'city',\n",
        "    'state',\n",
        "    'store_type',\n",
        "    'holiday_type',\n",
        "    'locale',\n",
        "    'locale_name',\n",
        "    'description'\n",
        "]\n",
        "\n",
        "for col in CAT_COLS:\n",
        "    X_full[col] = X_full[col].astype(\"category\")\n"
      ],
      "metadata": {
        "id": "dr2HL1F2-5PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgb_model = lgb.Booster(\n",
        "    model_file=\"models/lightgbm/baseline_lightgbm.txt\"\n",
        ")\n",
        "\n",
        "y_pred_lgb_log = lgb_model.predict(\n",
        "    X_full,\n",
        "    num_iteration=lgb_model.best_iteration\n",
        ")\n",
        "\n",
        "y_true_ml = np.expm1(y_full.values)\n",
        "y_pred_ml= np.expm1(y_pred_lgb_log)\n"
      ],
      "metadata": {
        "id": "sClFcko-_JdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on DL(Seq2Seq) Model"
      ],
      "metadata": {
        "id": "fCrrM0XzGPoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DL Features map and scaler\n",
        "import json, joblib\n",
        "\n",
        "with open(\"models/dl_feature&Scaler/dl_feature_map.json\", \"r\") as f:\n",
        "    feature_map = json.load(f)\n",
        "\n",
        "NUMERIC_FEATURES = feature_map[\"numeric_features\"]\n",
        "CATEGORICAL_FEATURES = feature_map[\"categorical_features\"]\n",
        "DL_FEATURES = feature_map[\"dl_features_order\"]\n",
        "category_maps = feature_map[\"category_maps\"]\n",
        "WINDOW_SIZE = feature_map[\"window_size\"]\n",
        "\n",
        "scaler = joblib.load(\"models/seq2seq_model/scaler.pkl\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OflhT5_v55i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Categories\n",
        "df = train.copy()\n",
        "\n",
        "def encode_categories(df, maps):\n",
        "    df = df.copy()\n",
        "    for col, mp in maps.items():\n",
        "        df[col] = df[col].astype(str).map(mp).fillna(0).astype(\"int32\")\n",
        "    return df\n",
        "\n",
        "df = encode_categories(df, category_maps)\n",
        "df[NUMERIC_FEATURES] = scaler.transform(df[NUMERIC_FEATURES])\n"
      ],
      "metadata": {
        "id": "08FG_nCi7FFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sliding Window Function\n",
        "def sliding_window_generator(\n",
        "    df,\n",
        "    window_size,\n",
        "    horizon,\n",
        "    feature_cols,\n",
        "    target_col,\n",
        "    batch_size=256,\n",
        "):\n",
        "    X_batch, y_batch = [], []\n",
        "\n",
        "    for _, gdf in df.groupby([\"store_nbr\", \"family\"]):\n",
        "        gdf = gdf.sort_values(\"date\")\n",
        "\n",
        "        X = gdf[feature_cols].values.astype(\"float32\")\n",
        "        y = gdf[target_col].values.astype(\"float32\")\n",
        "\n",
        "        if len(gdf) < window_size + horizon:\n",
        "            continue\n",
        "\n",
        "        for i in range(len(gdf) - window_size - horizon + 1):\n",
        "            X_batch.append(X[i:i+window_size])\n",
        "            y_batch.append(y[i+window_size+horizon-1])\n",
        "\n",
        "            if len(X_batch) == batch_size:\n",
        "                yield np.array(X_batch), np.array(y_batch)\n",
        "                X_batch, y_batch = [], []\n",
        "\n",
        "    if X_batch:\n",
        "        yield np.array(X_batch), np.array(y_batch)\n",
        "\n",
        "## tf.data Dataset Wrapper\n",
        "WINDOW_SIZE = 28\n",
        "HORIZON = 1\n",
        "TARGET = \"sales_log\"\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def make_dataset(df, shuffle=False):\n",
        "    ds = tf.data.Dataset.from_generator(\n",
        "        lambda: sliding_window_generator(\n",
        "            df, WINDOW_SIZE, HORIZON, DL_FEATURES, TARGET, BATCH_SIZE\n",
        "        ),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(\n",
        "                shape=(None, WINDOW_SIZE, len(DL_FEATURES)),\n",
        "                dtype=tf.float32\n",
        "            ),\n",
        "            tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
        "        ),\n",
        "    )\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(1024)\n",
        "    return ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zlPMvwIs6zmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dl_ds = make_dataset(df, shuffle=False)"
      ],
      "metadata": {
        "id": "_dzdPEFjDMq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt Seq2Seq Input\n",
        "NUM_NUMERIC = len(NUMERIC_FEATURES)\n",
        "NUM_CATEGORICAL = len(CATEGORICAL_FEATURES)\n",
        "\n",
        "def adapt_batch(X_batch):\n",
        "    X_num = X_batch[:, :, :NUM_NUMERIC]\n",
        "\n",
        "    X_cat = [\n",
        "        X_batch[:, :, NUM_NUMERIC + i].astype(\"int32\")\n",
        "        for i in range(NUM_CATEGORICAL)\n",
        "    ]\n",
        "\n",
        "    # Decoder input (teacher forcing placeholder)\n",
        "    y_dec = np.zeros((X_batch.shape[0], 1, 1), dtype=\"float32\")\n",
        "\n",
        "    return [X_num] + X_cat + [y_dec]\n"
      ],
      "metadata": {
        "id": "wQotjHVdDfDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Seq2Seq Model\n",
        "def rmsle_tf(y_true, y_pred):\n",
        "    y_true = tf.exp(y_true)\n",
        "    y_pred = tf.exp(y_pred)\n",
        "    return tf.sqrt(\n",
        "        tf.reduce_mean(\n",
        "            tf.square(tf.math.log1p(y_pred) - tf.math.log1p(y_true))\n",
        "        )\n",
        "    )\n",
        "\n",
        "seq2seq_model = tf.keras.models.load_model(\n",
        "    MODEL_PATH / 'seq2seq_model' / 'seq2seq_model.keras',\n",
        "    custom_objects={'rmsle_tf': rmsle_tf}\n",
        ")"
      ],
      "metadata": {
        "id": "NCng-JdXETKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on DL Dataset\n",
        "y_true_all = []\n",
        "y_pred_all = []\n",
        "\n",
        "for X_batch, y_batch in full_dl_ds:\n",
        "    X_batch = X_batch.numpy()\n",
        "    y_batch = y_batch.numpy()\n",
        "\n",
        "    inputs = adapt_batch(X_batch)\n",
        "\n",
        "    preds = seq2seq_model.predict(\n",
        "        inputs,\n",
        "        batch_size=len(y_batch),\n",
        "        verbose=0\n",
        "    ).reshape(-1)\n",
        "\n",
        "    y_true_all.append(y_batch)\n",
        "    y_pred_all.append(preds)\n"
      ],
      "metadata": {
        "id": "uXfE99HyECQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all\n",
        "y_true_dl_log = np.concatenate(y_true_all)\n",
        "y_pred_dl_log = np.concatenate(y_pred_all)\n",
        "\n",
        "# Back to Original Scale\n",
        "y_true_dl = np.expm1(y_true_dl_log)\n",
        "y_pred_dl = np.expm1(y_pred_dl_log)\n"
      ],
      "metadata": {
        "id": "BrXf-CWUE3qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics"
      ],
      "metadata": {
        "id": "GxX56PqlHdk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def rmsle(y_true, y_pred):\n",
        "    y_pred = np.maximum(y_pred, 0)\n",
        "    return np.sqrt(\n",
        "        mean_squared_log_error(y_true, np.maximum(y_pred, 0))\n",
        "    )\n",
        "\n",
        "metrics = {\n",
        "    \"LightGBM\": {\n",
        "        \"RMSLE\": rmsle(y_true_ml, y_pred_ml),\n",
        "        \"MAE\": mean_absolute_error(y_true_ml, y_pred_ml),\n",
        "    },\n",
        "    \"Seq2Seq\": {\n",
        "        \"RMSLE\": rmsle(y_true_dl, y_pred_dl),\n",
        "        \"MAE\": mean_absolute_error(y_true_dl, y_pred_dl),\n",
        "    }\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics).T\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "lNZMedRgHkwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization Actual Vs Predicted\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_true_ml, y_pred_ml, alpha=0.3, label=\"LightGBM\")\n",
        "plt.scatter(y_true_dl, y_pred_dl, alpha=0.3, label=\"Seq2Seq\")\n",
        "plt.plot([0, y_true_ml.max()], [0, y_true_ml.max()], \"r--\")\n",
        "plt.xlabel(\"Actual Sales\")\n",
        "plt.ylabel(\"Predicted Sales\")\n",
        "plt.legend()\n",
        "plt.title(\"Actual vs Predicted\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eTAfG3XSehdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time Series Plot\n",
        "n = 200  # first N samples\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(y_true_ml[:n], label=\"Actual\", linewidth=2)\n",
        "plt.plot(y_true_dl[:n], label=\"Actual\", linewidth=2)\n",
        "plt.plot(y_pred_ml[:n], label=\"LightGBM\")\n",
        "plt.plot(y_pred_dl[:n], label=\"Seq2Seq\")\n",
        "plt.legend()\n",
        "plt.title(\"Time Series Forecast Comparison\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E7o_3B0FjIl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Distribution\n",
        "err_lgbm = y_true_ml - y_pred_ml\n",
        "err_seq2seq = y_true_dl - y_pred_dl\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(err_lgbm, bins=50, alpha=0.6, label=\"LightGBM\")\n",
        "plt.hist(err_seq2seq, bins=50, alpha=0.6, label=\"Seq2Seq\")\n",
        "plt.legend()\n",
        "plt.title(\"Error Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uSYXX8SeJ97b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNlU_qlHMFUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}