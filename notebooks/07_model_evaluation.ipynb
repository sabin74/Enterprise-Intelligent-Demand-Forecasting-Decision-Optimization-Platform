{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "## Best ML vs Best DL\n",
        "### Evaluation & Visualization\n",
        "### Models\n",
        " - Best ML: LightGBM\n",
        " - Best DL: Seq2Seq"
      ],
      "metadata": {
        "id": "5jFf8wWbZONs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone GitHub Repository\n",
        "!git clone https://github.com/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform.git\n",
        ""
      ],
      "metadata": {
        "id": "owqiMcfJZscN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_squared_log_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "otHRFH0cYKGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Project Root\n",
        "os.chdir('/content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform')\n",
        "print(\"Current Directory: \", os.getcwd())"
      ],
      "metadata": {
        "id": "PUdZ1LtVbiyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = Path('models')\n",
        "REPORT_PATH = Path('data/reports')\n",
        "REPORT_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "-YLZH73UaHwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Original Data\n",
        "train = pd.read_parquet('data/features/train_features.parquet')\n",
        "test = pd.read_parquet('data/features/test_features.parquet')"
      ],
      "metadata": {
        "id": "ftwp1QFckVY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory Optimization (reduce memory usage)\n",
        "def reduce_mem_usage(df, ):\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == \"float64\":\n",
        "      df[col] = df[col].astype(\"float32\")\n",
        "    elif df[col].dtype == \"int64\":\n",
        "      df[col] = df[col].astype(\"int32\")\n",
        "  return df\n",
        "\n",
        "train = reduce_mem_usage(train)\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "EbL5bgO3mSdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Handling and Sorting\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "train = train.sort_values(\n",
        "    ['store_nbr', 'family', 'date']\n",
        ").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "MsIR9vM3mlkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop NaN values in Lag/Roll Features\n",
        "lag_cols = [col for col in train.columns if \"lag\" in col or \"roll\" in col]\n",
        "train = train.dropna(subset=lag_cols)"
      ],
      "metadata": {
        "id": "hnAbDw4pmu7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Ml and DL Features\n",
        "with open(MODEL_PATH /'dl_feature&Scaler' /'dl_feature_map.json', 'r') as f:\n",
        "    dl_feature_map = json.load(f)\n",
        "\n",
        "scaler = joblib.load(MODEL_PATH / 'seq2seq_model'/ 'scaler.pkl')\n",
        "\n",
        "\n",
        "ml_feature_importances = pd.read_csv(\n",
        "    MODEL_PATH /'lightgbm' /'lgb_feature_importance.csv'\n",
        ")\n",
        "\n",
        "DL_FEATURES = dl_feature_map['dl_features_order']\n",
        "DL_NUMERICAL_FEATURES = dl_feature_map['numeric_features']\n",
        "DL_CATEGORICAL_FEATURES = dl_feature_map['categorical_features']\n",
        "\n",
        "ML_FEATURES = ml_feature_importances.feature.values"
      ],
      "metadata": {
        "id": "oy3eTwiSnE07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build rmsle_tf function for seq2seq model\n",
        "def rmsle_tf(y_true, y_pred):\n",
        "    y_true = tf.exp(y_true)\n",
        "    y_pred = tf.exp(y_pred)\n",
        "    return tf.sqrt(\n",
        "        tf.reduce_mean(\n",
        "            tf.square(tf.math.log1p(y_pred) - tf.math.log1p(y_true))\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "mAAi2QP_sweV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best Model\n",
        "lgbm_model = lgb.Booster(\n",
        "    model_file=MODEL_PATH / 'lightgbm' / 'baseline_lightgbm.txt'\n",
        ")\n",
        "\n",
        "seq2seq_model = tf.keras.models.load_model(\n",
        "    MODEL_PATH / 'seq2seq_model' / 'seq2seq_model.keras',\n",
        "    custom_objects={'rmsle_tf': rmsle_tf}\n",
        ")"
      ],
      "metadata": {
        "id": "cbryB4VeaZKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction on Validation Set\n",
        " - X_val_ml → 2D (samples, features)\n",
        " - X_val_dl → 3D (samples, window, features)\n",
        " - y_val → log1p(sales)"
      ],
      "metadata": {
        "id": "cwr5ZfL2do-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare ML validation Data\n",
        "X_val_ml = train[ML_FEATURES].values\n",
        "y_val = train[\"sales_log\"].values\n",
        "\n",
        "# Categorical Features\n",
        "ML_CAT_COLS = train.select_dtypes(include='category').columns.tolist()\n",
        "\n",
        "lgb_valid = lgb.Dataset(\n",
        "    X_val_ml,\n",
        "    label=y_val,\n",
        "    categorical_feature=ML_CAT_COLS,\n",
        "    free_raw_data=False\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "QULWjONvnjuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Encode Categoricals (Integer IDs for Embeddings)\n",
        "# Build Category\n",
        "category_maps = {}\n",
        "\n",
        "for col in DL_CATEGORICAL_FEATURES:\n",
        "  category_maps[col] = {\n",
        "      v: i + 1 for i, v in enumerate(train[col].astype(str).unique())\n",
        "    }\n",
        "\n",
        "# Apply Encoding\n",
        "def encode_categories(df, maps):\n",
        "  df = df.copy()\n",
        "  for col, mp in maps.items():\n",
        "    df[col] = df[col].astype(str).map(mp).fillna(0).astype(\"int32\")\n",
        "  return df\n",
        "\n",
        "ml_train_df = encode_categories(train, category_maps)\n",
        "\n",
        "ml_train_df[DL_NUMERICAL_FEATURES] = scaler.transform(ml_train_df[DL_NUMERICAL_FEATURES])"
      ],
      "metadata": {
        "id": "4NENlLdGn-m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sliding Window Function\n",
        "def sliding_window_generator(\n",
        "    df,\n",
        "    window_size,\n",
        "    horizon,\n",
        "    feature_cols,\n",
        "    target_col,\n",
        "    batch_size=256,\n",
        "):\n",
        "    X_batch, y_batch = [], []\n",
        "\n",
        "    for _, gdf in df.groupby([\"store_nbr\", \"family\"]):\n",
        "        gdf = gdf.sort_values(\"date\")\n",
        "\n",
        "        X = gdf[feature_cols].values.astype(\"float32\")\n",
        "        y = gdf[target_col].values.astype(\"float32\")\n",
        "\n",
        "        if len(gdf) < window_size + horizon:\n",
        "            continue\n",
        "\n",
        "        for i in range(len(gdf) - window_size - horizon + 1):\n",
        "            X_batch.append(X[i:i+window_size])\n",
        "            y_batch.append(y[i+window_size+horizon-1])\n",
        "\n",
        "            if len(X_batch) == batch_size:\n",
        "                yield np.array(X_batch), np.array(y_batch)\n",
        "                X_batch, y_batch = [], []\n",
        "\n",
        "    if X_batch:\n",
        "        yield np.array(X_batch), np.array(y_batch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## tf.data Dataset Wrapper\n",
        "WINDOW_SIZE = 28\n",
        "HORIZON = 1\n",
        "TARGET = \"sales_log\"\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def make_dataset(df, shuffle=False):\n",
        "  ds = tf.data.Dataset.from_generator(\n",
        "    lambda: sliding_window_generator(\n",
        "      df, WINDOW_SIZE, HORIZON, DL_FEATURES, TARGET, BATCH_SIZE\n",
        "    ),\n",
        "    output_signature=(\n",
        "      tf.TensorSpec(shape=(None, WINDOW_SIZE, len(DL_FEATURES)), dtype=tf.float32),\n",
        "      tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
        "    ),\n",
        "  )\n",
        "  if shuffle:\n",
        "      ds = ds.shuffle(1024)\n",
        "  return ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Validation datasets\n",
        "valid_dl = make_dataset(ml_train_df)"
      ],
      "metadata": {
        "id": "npq7R6Kfn-hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict (log scale)\n",
        "y_pred_ml = lgbm_model.predict(lgb_valid)\n",
        "y_pred_dl = seq2seq_model.predict(valid_dl).ravel()\n",
        "\n",
        "# Back to original scale\n",
        "y_true = np.expm1(y_val)\n",
        "y_pred_ml = np.expm1(y_pred_ml)\n",
        "y_pred_dl = np.expm1(y_pred_dl)\n"
      ],
      "metadata": {
        "id": "D9N0hkZ0n-G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.columns"
      ],
      "metadata": {
        "id": "ma_8UmIen-Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_sliding_windows(df, window, horizon, features, target):\n",
        "    X, y = [], []\n",
        "\n",
        "    for _, gdf in df.groupby([\"store_nbr\", \"family\"]):\n",
        "        gdf = gdf.sort_values(\"date\")\n",
        "\n",
        "        values = gdf[features].values.astype(\"float32\")\n",
        "        labels = gdf[target].values.astype(\"float32\")\n",
        "\n",
        "        if len(gdf) < window + horizon:\n",
        "            continue\n",
        "\n",
        "        for i in range(len(gdf) - window - horizon + 1):\n",
        "            X.append(values[i:i+window])\n",
        "            y.append(labels[i+window+horizon-1])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_val_dl, y_val_dl = build_sliding_windows(\n",
        "    ml_train_df,\n",
        "    WINDOW_SIZE,\n",
        "    HORIZON,\n",
        "    DL_FEATURES,\n",
        "    TARGET,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "s8o65T_0n95O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BAsOOOgTn9vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eTAfG3XSehdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7o_3B0FjIl4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}