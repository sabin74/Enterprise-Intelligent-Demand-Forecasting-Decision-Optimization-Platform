{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "## Best ML vs Best DL\n",
        "### Evaluation & Visualization\n",
        "### Models\n",
        " - Best ML: LightGBM\n",
        " - Best DL: Seq2Seq"
      ],
      "metadata": {
        "id": "5jFf8wWbZONs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone GitHub Repository\n",
        "!git clone https://github.com/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform.git\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owqiMcfJZscN",
        "outputId": "4aa11d2b-e708-49fd-cac9-56fb4902e857"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform'...\n",
            "remote: Enumerating objects: 305, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 305 (delta 43), reused 33 (delta 6), pack-reused 216 (from 1)\u001b[K\n",
            "Receiving objects: 100% (305/305), 41.69 MiB | 39.75 MiB/s, done.\n",
            "Resolving deltas: 100% (155/155), done.\n",
            "Filtering content: 100% (22/22), 348.58 MiB | 90.92 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_squared_log_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "otHRFH0cYKGa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Project Root\n",
        "os.chdir('/content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform')\n",
        "print(\"Current Directory: \", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUdZ1LtVbiyN",
        "outputId": "27957043-4ab1-4e1f-ef1b-ee38f03f2d99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory:  /content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = Path('models')\n",
        "REPORT_PATH = Path('data/reports')\n",
        "REPORT_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "-YLZH73UaHwh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Original Data\n",
        "train = pd.read_parquet('data/features/train_features.parquet')\n",
        "test = pd.read_parquet('data/features/test_features.parquet')"
      ],
      "metadata": {
        "id": "ftwp1QFckVY4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory Optimization (reduce memory usage)\n",
        "def reduce_mem_usage(df, ):\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == \"float64\":\n",
        "      df[col] = df[col].astype(\"float32\")\n",
        "    elif df[col].dtype == \"int64\":\n",
        "      df[col] = df[col].astype(\"int32\")\n",
        "  return df\n",
        "\n",
        "train = reduce_mem_usage(train)\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbL5bgO3mSdG",
        "outputId": "ca91f85c-6001-48fb-885a-f82b14d2f63c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Handling and Sorting\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "train = train.sort_values(\n",
        "    ['store_nbr', 'family', 'date']\n",
        ").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "MsIR9vM3mlkc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop NaN values in Lag/Roll Features\n",
        "lag_cols = [col for col in train.columns if \"lag\" in col or \"roll\" in col]\n",
        "train = train.dropna(subset=lag_cols)"
      ],
      "metadata": {
        "id": "hnAbDw4pmu7Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Ml and DL Features\n",
        "with open(MODEL_PATH /'dl_feature&Scaler' /'dl_feature_map.json', 'r') as f:\n",
        "    dl_feature_map = json.load(f)\n",
        "\n",
        "scaler = joblib.load(MODEL_PATH / 'seq2seq_model'/ 'scaler.pkl')\n",
        "\n",
        "\n",
        "ml_feature_importances = pd.read_csv(\n",
        "    MODEL_PATH /'lightgbm' /'lgb_feature_importance.csv'\n",
        ")\n",
        "\n",
        "DL_FEATURES = dl_feature_map['dl_features_order']\n",
        "DL_NUMERICAL_FEATURES = dl_feature_map['numeric_features']\n",
        "DL_CATEGORICAL_FEATURES = dl_feature_map['categorical_features']\n",
        "\n",
        "ML_FEATURES = ml_feature_importances.feature.values"
      ],
      "metadata": {
        "id": "oy3eTwiSnE07"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build rmsle_tf function for seq2seq model\n",
        "def rmsle_tf(y_true, y_pred):\n",
        "    y_true = tf.exp(y_true)\n",
        "    y_pred = tf.exp(y_pred)\n",
        "    return tf.sqrt(\n",
        "        tf.reduce_mean(\n",
        "            tf.square(tf.math.log1p(y_pred) - tf.math.log1p(y_true))\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "mAAi2QP_sweV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best Model\n",
        "lgbm_model = lgb.Booster(\n",
        "    model_file=MODEL_PATH / 'lightgbm' / 'baseline_lightgbm.txt'\n",
        ")\n",
        "\n",
        "seq2seq_model = tf.keras.models.load_model(\n",
        "    MODEL_PATH / 'seq2seq_model' / 'seq2seq_model.keras',\n",
        "    custom_objects={'rmsle_tf': rmsle_tf}\n",
        ")"
      ],
      "metadata": {
        "id": "cbryB4VeaZKT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction on Validation Set\n",
        " - X_val_ml → 2D (samples, features)\n",
        " - X_val_dl → 3D (samples, window, features)\n",
        " - y_val → log1p(sales)"
      ],
      "metadata": {
        "id": "cwr5ZfL2do-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare ML validation Data\n",
        "X_val_ml = train[ML_FEATURES].values\n",
        "y_val = train[\"sales_log\"].values\n",
        "\n",
        "# Categorical Features\n",
        "ML_CAT_COLS = train.select_dtypes(include='category').columns.tolist()\n",
        "\n",
        "lgb_valid = lgb.Dataset(\n",
        "    X_val_ml,\n",
        "    label=y_val,\n",
        "    categorical_feature=ML_CAT_COLS,\n",
        "    free_raw_data=False\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "QULWjONvnjuv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Encode Categoricals (Integer IDs for Embeddings)\n",
        "# Build Category\n",
        "category_maps = {}\n",
        "\n",
        "for col in DL_CATEGORICAL_FEATURES:\n",
        "  category_maps[col] = {\n",
        "      v: i + 1 for i, v in enumerate(train[col].astype(str).unique())\n",
        "    }\n",
        "\n",
        "# Apply Encoding\n",
        "def encode_categories(df, maps):\n",
        "  df = df.copy()\n",
        "  for col, mp in maps.items():\n",
        "    df[col] = df[col].astype(str).map(mp).fillna(0).astype(\"int32\")\n",
        "  return df\n",
        "\n",
        "ml_train_df = encode_categories(train, category_maps)\n",
        "\n",
        "ml_train_df[DL_NUMERICAL_FEATURES] = scaler.transform(ml_train_df[DL_NUMERICAL_FEATURES])"
      ],
      "metadata": {
        "id": "4NENlLdGn-m8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sliding Window Function\n",
        "def sliding_window_generator(\n",
        "    df,\n",
        "    window_size,\n",
        "    horizon,\n",
        "    feature_cols,\n",
        "    target_col,\n",
        "    batch_size=256,\n",
        "):\n",
        "    X_batch, y_batch = [], []\n",
        "\n",
        "    for _, gdf in df.groupby([\"store_nbr\", \"family\"]):\n",
        "        gdf = gdf.sort_values(\"date\")\n",
        "\n",
        "        X = gdf[feature_cols].values.astype(\"float32\")\n",
        "        y = gdf[target_col].values.astype(\"float32\")\n",
        "\n",
        "        if len(gdf) < window_size + horizon:\n",
        "            continue\n",
        "\n",
        "        for i in range(len(gdf) - window_size - horizon + 1):\n",
        "            X_batch.append(X[i:i+window_size])\n",
        "            y_batch.append(y[i+window_size+horizon-1])\n",
        "\n",
        "            if len(X_batch) == batch_size:\n",
        "                yield np.array(X_batch), np.array(y_batch)\n",
        "                X_batch, y_batch = [], []\n",
        "\n",
        "    if X_batch:\n",
        "        yield np.array(X_batch), np.array(y_batch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## tf.data Dataset Wrapper\n",
        "WINDOW_SIZE = 28\n",
        "HORIZON = 1\n",
        "TARGET = \"sales_log\"\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def make_dataset(df, shuffle=False):\n",
        "  ds = tf.data.Dataset.from_generator(\n",
        "    lambda: sliding_window_generator(\n",
        "      df, WINDOW_SIZE, HORIZON, DL_FEATURES, TARGET, BATCH_SIZE\n",
        "    ),\n",
        "    output_signature=(\n",
        "      tf.TensorSpec(shape=(None, WINDOW_SIZE, len(DL_FEATURES)), dtype=tf.float32),\n",
        "      tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
        "    ),\n",
        "  )\n",
        "  if shuffle:\n",
        "      ds = ds.shuffle(1024)\n",
        "  return ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Validation datasets\n",
        "valid_dl = make_dataset(train)"
      ],
      "metadata": {
        "id": "npq7R6Kfn-hY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict (log scale)\n",
        "y_pred_ml = lgbm_model.predict(lgb_valid)\n",
        "y_pred_dl = seq2seq_model.predict(valid_dl).ravel()\n",
        "\n",
        "# Back to original scale\n",
        "y_true = np.expm1(y_val)\n",
        "y_pred_ml = np.expm1(y_pred_ml)\n",
        "y_pred_dl = np.expm1(y_pred_dl)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "D9N0hkZ0n-G7",
        "outputId": "2619cf8d-e9e5-4939-b1da-2dcc6c3385b0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1286218030.py:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  for _, gdf in df.groupby([\"store_nbr\", \"family\"]):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: could not convert string to float: 'AUTOMOTIVE'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-1286218030.py\", line 15, in sliding_window_generator\n    X = gdf[feature_cols].values.astype(\"float32\")\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nValueError: could not convert string to float: 'AUTOMOTIVE'\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-693566357.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict (log scale)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Back to original scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6004\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6005\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6006\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: could not convert string to float: 'AUTOMOTIVE'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-1286218030.py\", line 15, in sliding_window_generator\n    X = gdf[feature_cols].values.astype(\"float32\")\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nValueError: could not convert string to float: 'AUTOMOTIVE'\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ma_8UmIen-Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s8o65T_0n95O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BAsOOOgTn9vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eTAfG3XSehdA"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7o_3B0FjIl4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}