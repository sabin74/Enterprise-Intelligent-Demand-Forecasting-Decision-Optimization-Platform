{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "33007253-b523-4463-b120-bfb2ed988094",
      "metadata": {
        "id": "33007253-b523-4463-b120-bfb2ed988094"
      },
      "source": [
        "<h1 style='color:Green'>Baseline Modeling</h1>\n",
        "<h3>ðŸ“Œ Objectives </h3>\n",
        "<pre>\n",
        "  Establish simple, interpretable benchmark models to:\n",
        "  - Validate feature quality\n",
        "  - Create RMSLE reference scores\n",
        "  - Compare against advanced ML/DL later\n",
        "\n",
        " No heavy tuning, no leakage, no deep learning.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f0475d3-3ca2-4734-8c81-019fe739d02b",
      "metadata": {
        "id": "8f0475d3-3ca2-4734-8c81-019fe739d02b"
      },
      "source": [
        "<h2 style='color:Green'>Load Feature Data</h2>\n",
        "<h3>ðŸŽ¯ Goal </h3>\n",
        "<pre>\n",
        "  - Load engineered features\n",
        "  - Drop only lag/rolling NaNs\n",
        "  - Keep time order intact\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Clone GitHub Repository</h3>"
      ],
      "metadata": {
        "id": "crP9iR73udU4"
      },
      "id": "crP9iR73udU4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone GitHub Repository\n",
        "!git clone https://github.com/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3z6BaK8P2w-",
        "outputId": "9311943b-d5ec-4b5f-b62a-e8f234ee59f3"
      },
      "id": "a3z6BaK8P2w-",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 36 (delta 6), reused 26 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 21.62 MiB | 36.41 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Filtering content: 100% (11/11), 315.52 MiB | 52.06 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Project Root\n",
        "\n",
        "This keeps paths identical to local setup."
      ],
      "metadata": {
        "id": "e14gpiENuzd5"
      },
      "id": "e14gpiENuzd5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set  PROJECT_ROOT\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform\"\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "print(\"Current directory:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doh-3EJLPzm-",
        "outputId": "35ce4d87-90bd-49a7-a0ae-7f131fb1f837"
      },
      "id": "Doh-3EJLPzm-",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Feature Data\n",
        "ðŸŽ¯ Goal\n",
        " - Load engineered data\n",
        " - Drop only lag/rolling NaNs\n",
        " - Preserve time order\n",
        " - Avoid memory waste"
      ],
      "metadata": {
        "id": "PLhT9Mh2vCxg"
      },
      "id": "PLhT9Mh2vCxg"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "b2ef3b39-fa2e-4954-8e7e-e05f89d01a86",
      "metadata": {
        "id": "b2ef3b39-fa2e-4954-8e7e-e05f89d01a86"
      },
      "outputs": [],
      "source": [
        "# Import and Load Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e408e745-9b85-4dcd-8d0d-0d9f00e997ae",
      "metadata": {
        "id": "e408e745-9b85-4dcd-8d0d-0d9f00e997ae"
      },
      "outputs": [],
      "source": [
        "# Load Feature Dataset from Repo\n",
        "FEATURE_DATA = Path(\"data/features\")\n",
        "\n",
        "train = pd.read_parquet(FEATURE_DATA / \"train_features.parquet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b6a509c2-3c0e-43da-b7a2-d8f68b1066a8",
      "metadata": {
        "id": "b6a509c2-3c0e-43da-b7a2-d8f68b1066a8"
      },
      "outputs": [],
      "source": [
        "# Convert Date and Sort\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "\n",
        "train = train.sort_values(\n",
        "    ['store_nbr', 'family', 'date']\n",
        ").reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ebd54f87-4de2-4f62-9ccb-31336f9466c2",
      "metadata": {
        "id": "ebd54f87-4de2-4f62-9ccb-31336f9466c2"
      },
      "outputs": [],
      "source": [
        "# Identify Lag and Rolling Columns\n",
        "lag_roll_cols = [\n",
        "    col for col in train.columns\n",
        "    if (\"lag\" in col) or (\"roll\" in col)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop NaN in lag/rolling features\n",
        "train_model = train.dropna(\n",
        "    subset = lag_roll_cols\n",
        ").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "k0uCJH2BPOy7"
      },
      "id": "k0uCJH2BPOy7",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Target & Feature Sets\n",
        "### Target Options\n",
        "  - sales_log (preferred for RMSLE)\n",
        "###Feature Sets\n",
        "  - Time features\n",
        "  - Lag features\n",
        "  - Rolling features\n",
        "  - Promotions\n",
        "  - Oil\n",
        "  - Encodings"
      ],
      "metadata": {
        "id": "N0vu-ppbvkuE"
      },
      "id": "N0vu-ppbvkuE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Targe Variable\n",
        "TARGET = 'sales_log'"
      ],
      "metadata": {
        "id": "CJbs2i4zSeR8"
      },
      "id": "CJbs2i4zSeR8",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Feature Groups\n",
        "TIME_FEATURES = [\n",
        "    \"day\", \"week_of_year\", \"monty\", \"year\",\n",
        "    \"day_of_week\", \"is_weekend\", \"is_payday\"\n",
        "]\n",
        "\n",
        "LAG_FEATURES = [\n",
        "    \"sales_lag_1\", \"sales_lag_7\",\n",
        "    \"sales_lag_14\", \"sales_lag_28\"\n",
        "]\n",
        "\n",
        "ROLL_FEATURES = [\n",
        "    \"sales_roll_mean_7\", \"sales_roll_mean_14\", \"sales_roll_mean_28\",\n",
        "    \"sales_roll_std_7\", \"sales_roll_std_14\", \"sales_roll_std_28\"\n",
        "]\n",
        "\n",
        "PROMO_FEATURES = [\n",
        "    \"onpromotion\",\n",
        "    \"promo_lag_1\", \"promo_lag_7\",\n",
        "    \"promo_freq_7\", \"promo_freq_14\", \"promo_freq_28\",\n",
        "    \"promo_roll_sum_7\", \"promo_roll_sum_14\", \"promo_roll_sum_28\"\n",
        "]\n",
        "\n",
        "OIL_FEATURES = [\n",
        "    \"dcoilwtico\", \"oil_lag_7\", \"oil_lag_14\", \"oil_lag_28\"\n",
        "]\n",
        "\n",
        "ENCODING_FEATURES = [\n",
        "    \"store_te\", \"family_te\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "xbloI77JS4W6"
      },
      "id": "xbloI77JS4W6",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Feature List\n",
        "FEATURES = (\n",
        "    TIME_FEATURES + LAG_FEATURES + ROLL_FEATURES +\n",
        "    PROMO_FEATURES + OIL_FEATURES + ENCODING_FEATURES\n",
        ")"
      ],
      "metadata": {
        "id": "DxF-qp35TE4g"
      },
      "id": "DxF-qp35TE4g",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which features actually exist\n",
        "print(f\"Total features in list: {len(FEATURES)}\")\n",
        "print(f\"Features missing from train_model:\")\n",
        "missing_features = [f for f in FEATURES if f not in train_model.columns]\n",
        "for f in missing_features:\n",
        "    print(f\"  - {f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggaMzS9kRcrj",
        "outputId": "3a81551d-d688-47b6-9aaa-03996428894a"
      },
      "id": "ggaMzS9kRcrj",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total features in list: 32\n",
            "Features missing from train_model:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing Modeling Metrics\n",
        "X = train_model[FEATURES]\n",
        "y = train_model[TARGET]"
      ],
      "metadata": {
        "id": "UIQfQt0lTqFq"
      },
      "id": "UIQfQt0lTqFq",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time-Based Validation Strategy\n",
        "**Why**: Time series â‰  random split\n",
        "### Validation Method\n",
        "  - Last N days as validation\n",
        "  - Example:\n",
        "    - Train: up to 2017-07-15\n",
        "    - Valid: 2017-07-16 â†’ 2017-08-15"
      ],
      "metadata": {
        "id": "iGuhwBk_wYOQ"
      },
      "id": "iGuhwBk_wYOQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Validation Cutoff Date\n",
        "TRAIN_END_DATE = \"2017-07-15\""
      ],
      "metadata": {
        "id": "QCZkCEQ8UBGU"
      },
      "id": "QCZkCEQ8UBGU",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Time Based Split\n",
        "train_mask = train_model['date'] <= TRAIN_END_DATE\n",
        "valid_mask = train_model['date'] > TRAIN_END_DATE\n",
        "\n",
        "X_train = X[train_mask]\n",
        "y_train = y[train_mask]\n",
        "\n",
        "X_valid = X[valid_mask]\n",
        "y_valid = y[valid_mask]"
      ],
      "metadata": {
        "id": "MPC8zDG5Uxc2"
      },
      "id": "MPC8zDG5Uxc2",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Also keep the full train_model rows for validation (for accessing lag columns)\n",
        "train_valid = train_model[valid_mask].reset_index(drop=True)\n",
        "\n",
        "print(\"DATA SPLIT SUMMARY:\\n\")\n",
        "print(f\"Train dates: {train_model[train_mask]['date'].min().date()} to {train_model[train_mask]['date'].max().date()}\")\n",
        "print(f\"Validation dates: {train_model[valid_mask]['date'].min().date()} to {train_model[valid_mask]['date'].max().date()}\")\n",
        "print(f\"Train samples: {len(X_train):,}\")\n",
        "print(f\"Validation samples: {len(X_valid):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jPvZcX2RuuU",
        "outputId": "8646cc69-5966-48d0-e93d-3709f75315ea"
      },
      "id": "3jPvZcX2RuuU",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA SPLIT SUMMARY:\n",
            "\n",
            "Train dates: 2013-01-29 to 2017-07-15\n",
            "Validation dates: 2017-07-16 to 2017-08-15\n",
            "Train samples: 2,949,210\n",
            "Validation samples: 55,242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BASELINE MODEL 1 â€“ NAIVE & MOVING AVERAGE\n",
        "### Goal\n",
        "  - Establish simple benchmark scores\n",
        "  - Validate feature correctness\n",
        "  - Create RMSLE reference"
      ],
      "metadata": {
        "id": "Eaxy9kb2w41z"
      },
      "id": "Eaxy9kb2w41z"
    },
    {
      "cell_type": "code",
      "source": [
        "## Define Evaluation Metrics (RMSLE)\n",
        "def rmsle(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Root Mean Squared Log Error\n",
        "    \"\"\"\n",
        "    y_true = np.maximum(0, y_true)\n",
        "    y_pred = np.maximum(0, y_pred)\n",
        "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "ALcwNULbw2Mm"
      },
      "id": "ALcwNULbw2Mm",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Validation Ground Truth\n",
        "y_valid_true = np.expm1(y_valid)"
      ],
      "metadata": {
        "id": "cqSEAlgbSMzB"
      },
      "id": "cqSEAlgbSMzB",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Prediction (log-space)\n",
        "naive_pred_log = X_valid[\"sales_lag_1\"]\n"
      ],
      "metadata": {
        "id": "9mTkMJHgSPIk"
      },
      "id": "9mTkMJHgSPIk",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Back to Original Scale\n",
        "naive_pred = np.expm1(naive_pred_log)\n"
      ],
      "metadata": {
        "id": "oxDzfNigWcMy"
      },
      "id": "oxDzfNigWcMy",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a safe inverse transform\n",
        "def safe_expm1(x, clip_max=1):\n",
        "    \"\"\"\n",
        "    Safely inverse log transform:\n",
        "    - clips extreme log values\n",
        "    - prevents overflow\n",
        "    \"\"\"\n",
        "    x = np.clip(x, a_min=None, a_max=clip_max)\n",
        "    return np.expm1(x)\n"
      ],
      "metadata": {
        "id": "tIUY27PEXG13"
      },
      "id": "tIUY27PEXG13",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate RMSLE\n",
        "naive_pred_log = X_valid[\"sales_lag_1\"]\n",
        "naive_pred = safe_expm1(naive_pred_log)\n",
        "\n",
        "naive_rmsle = rmsle(y_valid_true, naive_pred)\n",
        "\n",
        "print(f\"Naive Forecast RMSLE: {naive_rmsle:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Job__UOzWh9U",
        "outputId": "4f300135-4351-4111-9dcc-3c57f895a68a"
      },
      "id": "Job__UOzWh9U",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Forecast RMSLE: 3.78181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BASELINE MODEL 1 â€“ MOVING AVERAGE\n",
        "### Predict sales using rolling mean of past sales\\"
      ],
      "metadata": {
        "id": "wfu7gq9zZ65S"
      },
      "id": "wfu7gq9zZ65S"
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 day, 14 day & 28 day Average\n",
        "ma7_pred = safe_expm1(X_valid[\"sales_roll_mean_7\"])\n",
        "ma14_pred = safe_expm1(X_valid[\"sales_roll_mean_14\"])\n",
        "ma28_pred = safe_expm1(X_valid[\"sales_roll_mean_28\"])\n",
        "\n",
        "ma7_rmsle = rmsle(y_valid_true, ma7_pred)\n",
        "ma14_rmsle = rmsle(y_valid_true, ma14_pred)\n",
        "ma28_rmsle = rmsle(y_valid_true, ma28_pred)\n",
        "\n",
        "print(f\"MA-7 RMSLE:  {ma7_rmsle:.5f}\")\n",
        "print(f\"MA-14 RMSLE: {ma14_rmsle:.5f}\")\n",
        "print(f\"MA-28 RMSLE: {ma28_rmsle:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtqgqCziSPD1",
        "outputId": "f22cb2fc-80b8-43d7-f563-e5784d9f7b84"
      },
      "id": "JtqgqCziSPD1",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MA-7 RMSLE:  4.33326\n",
            "MA-14 RMSLE: 4.33324\n",
            "MA-28 RMSLE: 4.33324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model 3: Linear Regression (OLS)\n",
        "### ðŸŽ¯ Goal\n",
        "\n",
        "#### Learn linear relationships between:\n",
        " - time patterns\n",
        " - past sales (lags & rolling)\n",
        " - promotions\n",
        " - oil price\n",
        " - store / product encodings\n"
      ],
      "metadata": {
        "id": "LcxdjfrAcc_r"
      },
      "id": "LcxdjfrAcc_r"
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "def inverse_log(x):\n",
        "    return np.expm1(x)\n",
        "y_valid_pred_log = lr.predict(X_valid_scaled)\n",
        "\n",
        "y_valid_true = inverse_log(y_valid)\n",
        "y_valid_pred = np.maximum(inverse_log(y_valid_pred_log), 0)\n",
        "rmsle_lr = np.sqrt(\n",
        "    mean_squared_log_error(y_valid_true, y_valid_pred)\n",
        ")\n",
        "\n",
        "print(f\"Linear Regression RMSLE: {rmsle_lr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0rMD3HYViRX",
        "outputId": "708338d2-cac8-4d87-d08a-adcafd80df5a"
      },
      "id": "T0rMD3HYViRX",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression RMSLE: 0.9663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Initialize Ridge (alpha=1.0 is default, higher alpha = more regularization)\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and Inverse Transform\n",
        "y_valid_pred_log_ridge = ridge.predict(X_valid_scaled)\n",
        "y_valid_pred_ridge = np.maximum(np.expm1(y_valid_pred_log_ridge), 0)\n",
        "\n",
        "# Calculate RMSLE\n",
        "rmsle_ridge = np.sqrt(mean_squared_log_error(y_valid_true, y_valid_pred_ridge))\n",
        "\n",
        "print(f\"Ridge Regression RMSLE: {rmsle_ridge:.4f}\")"
      ],
      "metadata": {
        "id": "DBeaohVndr7w",
        "outputId": "c3d2f172-a7f1-46be-cf3d-10979f89c2c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DBeaohVndr7w",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression RMSLE: 0.9663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Initialize Lasso\n",
        "lasso = Lasso(alpha=0.01) # Lasso is sensitive to alpha; smaller values usually work better for log-data\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and Inverse Transform\n",
        "y_valid_pred_log_lasso = lasso.predict(X_valid_scaled)\n",
        "y_valid_pred_lasso = np.maximum(np.expm1(y_valid_pred_log_lasso), 0)\n",
        "\n",
        "# Calculate RMSLE\n",
        "rmsle_lasso = np.sqrt(mean_squared_log_error(y_valid_true, y_valid_pred_lasso))\n",
        "\n",
        "print(f\"Lasso Regression RMSLE: {rmsle_lasso:.4f}\")"
      ],
      "metadata": {
        "id": "rOYeAE1efZ4u",
        "outputId": "2db81d2d-9104-4a56-c9f4-50545441fb77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rOYeAE1efZ4u",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Regression RMSLE: 0.9657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize XGBoost Regressor\n",
        "# We use small learning_rate and more estimators for better generalization\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "xgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Predict and Inverse Transform\n",
        "y_pred_log_xgb = xgb_model.predict(X_valid)\n",
        "y_pred_xgb = np.maximum(np.expm1(y_pred_log_xgb), 0)\n",
        "\n",
        "# Calculate RMSLE\n",
        "rmsle_xgb = np.sqrt(mean_squared_log_error(y_valid_true, y_pred_xgb))\n",
        "print(f\"XGBoost RMSLE: {rmsle_xgb:.4f}\")"
      ],
      "metadata": {
        "id": "9BdjCQInff31",
        "outputId": "4c6a1b94-0093-40d2-cb20-cd868fc4137a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9BdjCQInff31",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost RMSLE: 0.3863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Initialize LightGBM\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "lgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    eval_metric='rmse')\n",
        "\n",
        "# Predict and Inverse Transform\n",
        "y_pred_log_lgb = lgb_model.predict(X_valid)\n",
        "y_pred_lgb = np.maximum(np.expm1(y_pred_log_lgb), 0)\n",
        "\n",
        "# Calculate RMSLE\n",
        "rmsle_lgb = np.sqrt(mean_squared_log_error(y_valid_true, y_pred_lgb))\n",
        "print(f\"LightGBM RMSLE: {rmsle_lgb:.4f}\")"
      ],
      "metadata": {
        "id": "IPGqvTOgf_j6",
        "outputId": "f898ecf3-fdde-4576-d678-ed9d110382e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IPGqvTOgf_j6",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.523150 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5206\n",
            "[LightGBM] [Info] Number of data points in the train set: 2949210, number of used features: 32\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Info] Start training from score 2.932884\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "LightGBM RMSLE: 0.3838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "olsBqYFngX0e"
      },
      "id": "olsBqYFngX0e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}