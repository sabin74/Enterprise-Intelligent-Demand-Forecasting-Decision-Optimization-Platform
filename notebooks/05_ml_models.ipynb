{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform/blob/main/notebooks/05_ml_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Machine Learning Models\n",
        "### Goal: Achieve strong performance\n",
        "### Models\n",
        " - Random Forest\n",
        " - XGBoost\n",
        " - LightGBM (primary model)\n",
        " - CatBoost\n",
        "### Techniques\n",
        " - Time-series cross-validation\n",
        " - Feature importance\n",
        " - Hyperparameter tuning (Optuna)\n",
        "### Output: Best ML model\n"
      ],
      "metadata": {
        "id": "udAV8u6HxaTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Setup & Data Preparation\n",
        "\n",
        " - Load feature-engineered dataset\n",
        " - Memory optimization (critical for Colab)\n",
        " - Final NaN handling (lag-safe)\n",
        "### Goal:\n",
        " - target (sales_log)\n",
        " - feature list\n",
        " - Time-based train/validation split"
      ],
      "metadata": {
        "id": "KPpmmb7Vx_71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone GitHub Repository\n",
        "!git clone https://github.com/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform.git"
      ],
      "metadata": {
        "id": "Dvqe5-pUxVul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Setup - Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gc"
      ],
      "metadata": {
        "id": "YDXgfaMVwohg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Project Root\n",
        "os.chdir(\"/content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform\")\n",
        "print(\"Current Directory: \", os.getcwd())"
      ],
      "metadata": {
        "id": "R1WQ84aT1ktw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Feature-Engineered Data\n",
        "DATA_DIR = Path(\"data/features\")\n",
        "\n",
        "train = pd.read_parquet(DATA_DIR / \"train_features.parquet\")"
      ],
      "metadata": {
        "id": "fmqo8AYa03v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory Optimization (reduce memory usage)\n",
        "def reduce_mem_usage(df, ):\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == \"float64\":\n",
        "      df[col] = df[col].astype(\"float32\")\n",
        "    elif df[col].dtype == \"int64\":\n",
        "      df[col] = df[col].astype(\"int32\")\n",
        "  return df\n",
        "\n",
        "train = reduce_mem_usage(train)\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "HCYzTF_s1WbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Handling and Sorting\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "train = train.sort_values(\n",
        "    ['store_nbr', 'family', 'date']\n",
        ").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7oM9T3E43NEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop NaN values in Lag/Roll Features\n",
        "# identify Lag/Roll Columns\n",
        "lag_cols = [col for col in train.columns if \"lag\" in col or \"roll\" in col]\n",
        "\n",
        "# Drop NaN\n",
        "initial_rows = len(train)\n",
        "\n",
        "train = train.dropna(subset=lag_cols)\n",
        "\n",
        "print(f\"Rows dropped: {initial_rows - len(train)}\")\n",
        "print(f\"Remaining Rows: {len(train)}\")\n",
        "print(f\"Loose Percentage: {100 * (initial_rows - len(train)) / initial_rows:.2f}\")"
      ],
      "metadata": {
        "id": "uC9VJ-qO3sBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Target and Features\n",
        "TARGET = 'sales_log'\n",
        "y = train[TARGET]"
      ],
      "metadata": {
        "id": "i2P9fkng7JV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features Selection\n",
        "# Drop unnecessaary Columns\n",
        "Drop_cols = ['id', 'date', 'sales', 'sales_log']\n",
        "\n",
        "FEATURES = [col for col in train.columns if col not in Drop_cols]\n",
        "\n",
        "X = train[FEATURES]"
      ],
      "metadata": {
        "id": "v5X76sP64efM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical Features\n",
        "CAT_COLS = train.select_dtypes(include='category').columns.tolist()\n",
        "CAT_COLS"
      ],
      "metadata": {
        "id": "3OBB_uMVBkkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time Based Train / Validation Split\n",
        "TRAIN_END_DATE = pd.to_datetime('2017-07-15')\n",
        "\n",
        "train_model = train.copy()\n",
        "train_mask = train_model['date'] <= TRAIN_END_DATE\n",
        "valid_mask = train_model['date'] > TRAIN_END_DATE\n",
        "\n",
        "X_train = X[train_mask]\n",
        "y_train = y[train_mask]\n",
        "\n",
        "X_valid = X[valid_mask]\n",
        "y_valid = y[valid_mask]"
      ],
      "metadata": {
        "id": "hpF65IZz4i73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Split Summary\n",
        "train_valid = train_model[valid_mask].reset_index(drop=True)\n",
        "\n",
        "print(\"DATA SPLIT SUMMARY:\\n\")\n",
        "print(f\"Train dates: {train_model[train_mask]['date'].min().date()} to {train_model[train_mask]['date'].max().date()}\")\n",
        "print(f\"Validation dates: {train_model[valid_mask]['date'].min().date()} to {train_model[valid_mask]['date'].max().date()}\")\n",
        "\n",
        "print(f\"\\nTrain Shape: {X_train.shape}\")\n",
        "print(f\"Validation Shape: {X_valid.shape}\")"
      ],
      "metadata": {
        "id": "VXTg_hOl79-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSLE Evaluation Function\n",
        "def rmsle(y_true, y_pred):\n",
        "  y_true = np.expm1(y_true)\n",
        "  y_pred = np.expm1(y_pred)\n",
        "  y_pred = np.maximum(y_pred, 0)\n",
        "  return np.sqrt(mean_squared_log_error(y_true, y_pred))"
      ],
      "metadata": {
        "id": "qgU0vAJD8tyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1. Random Forest Model\n",
        " - Captures non-linearity\n",
        " - Strong improvement over linear models\n",
        " - Gives feature importance intuition"
      ],
      "metadata": {
        "id": "vEAMyX4O-dK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "!pip install category_encoders\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from category_encoders import TargetEncoder"
      ],
      "metadata": {
        "id": "-NghnzJTIELc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Categorical Features\n",
        "\n",
        "te = TargetEncoder()\n",
        "X_train_te = te.fit_transform(X_train, y_train)\n",
        "X_valid_te = te.transform(X_valid)\n"
      ],
      "metadata": {
        "id": "hR5OL-4YBzCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RF Model\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=12,\n",
        "    min_samples_split=50,\n",
        "    min_samples_leaf=5,\n",
        "    max_features=\"sqrt\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "id": "e5luN7Cw9cFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train RF Model\n",
        "rf_model.fit(X_train_te, y_train)"
      ],
      "metadata": {
        "id": "dB2hpG-t_SLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Prediction\n",
        "rf_valid_pred = rf_model.predict(X_valid_te)\n",
        "rf_rmsle = rmsle(y_valid, rf_valid_pred)\n",
        "print(f\"Random Forest RMSLE: {rf_rmsle:.4f}\")"
      ],
      "metadata": {
        "id": "gR2tiYuHAG2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature Importances\n",
        "# Create Importance Dataframe\n",
        "rf_importance = pd.DataFrame({\n",
        "    'feature': X_train_te.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "# Sort by Importance\n",
        "rf_importance = rf_importance.sort_values(by='importance', ascending=False)"
      ],
      "metadata": {
        "id": "pkSc7uu5FQdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.barh(\n",
        "    rf_importance[\"feature\"][:20][::-1],\n",
        "    rf_importance[\"importance\"][:20][::-1]\n",
        ")\n",
        "plt.title(\"Random Forest Feature Importance (Top 20)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WyYs1AkkGl99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Feature Importances\n",
        "rf_importance.to_csv(\"rf_feature_importance.csv\", index=False)"
      ],
      "metadata": {
        "id": "nxK5Uc_hQK-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Target Encoder\n",
        "import joblib\n",
        "joblib.dump(te, \"models/target_encoder.pkl\")\n",
        "\n",
        "# Save Random Forest Model\n",
        "joblib.dump(rf_model, \"models/random_forest.pkl\")"
      ],
      "metadata": {
        "id": "kkFYvzz1PqWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2. XGBoost\n",
        " -  Industry-standard GBM\n",
        " -  Excellent with lag + sparse features\n",
        " -  Strong biasâ€“variance tradeoff\n",
        " -  Much faster & better than Random Forest"
      ],
      "metadata": {
        "id": "RAG3K-8MHQmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library\n",
        "!pip install -q xgboost\n",
        "\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "qUYFWB5BGrOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare XGBoost Dataset\n",
        "dtrain = xgb.DMatrix(X_train_te, label=y_train)\n",
        "dvalid = xgb.DMatrix(X_valid_te, label=y_valid)"
      ],
      "metadata": {
        "id": "jySP8oieHZMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define XGB Parameters\n",
        "xgb_params = {\n",
        "    \"objective\": \"reg:squarederror\",\n",
        "    \"eval_metric\": \"rmse\",\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"max_depth\": 8,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"tree_method\": \"hist\",   # fast & memory efficient\n",
        "    \"seed\": 42\n",
        "}"
      ],
      "metadata": {
        "id": "UtbO8BKBIsme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evals = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
        "\n",
        "xgb_model = xgb.train(\n",
        "    params=xgb_params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=500,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=50\n",
        ")\n"
      ],
      "metadata": {
        "id": "FeYCSkq0JHpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation prediction\n",
        "xgb_valid_pred = xgb_model.predict(dvalid)\n",
        "xgb_rmsle = rmsle(y_valid, xgb_valid_pred)\n",
        "print(f\"XGBoost RMSLE: {xgb_rmsle:.4f}\")"
      ],
      "metadata": {
        "id": "iQ70TQqmJk5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfitting Check - Train vs Valid\n",
        "xgb_train_pred = xgb_model.predict(dtrain)\n",
        "train_rmsle = rmsle(y_train, xgb_train_pred)\n",
        "valid_rmsle = xgb_rmsle\n",
        "\n",
        "print(f\"Train RMSLE: {train_rmsle:.4f}\")\n",
        "print(f\"Validation RMSLE: {valid_rmsle:.4f}\")"
      ],
      "metadata": {
        "id": "kOG6a4-zKm9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance - Top 20\n",
        "importances = xgb_model.get_score(importance_type=\"weight\")\n",
        "\n",
        "xgb_importance = pd.DataFrame({\n",
        "    \"feature\": list(importances.keys()),\n",
        "    \"importance\": list(importances.values())\n",
        "}).sort_values(by=\"importance\", ascending=False)\n",
        "\n",
        "xgb_importance = xgb_importance.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "_uHVwpHbK3uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.barh(\n",
        "    xgb_importance[\"feature\"][:20][::-1],\n",
        "    xgb_importance[\"importance\"][:20][::-1]\n",
        ")\n",
        "plt.title(\"XGBoost Feature Importance (Top 20)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "daFRI4NAMGX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Feature Importances\n",
        "xgb_importance.to_csv(\"lgb_feature_importance.csv\", index=False)"
      ],
      "metadata": {
        "id": "1MJqN-a6QQpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save XGBoost\n",
        "xgb_model.save_model(\"models/xgboost.json\")"
      ],
      "metadata": {
        "id": "1ILW7_pQQD8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 - LightGBM (PRIMARY MODEL)\n",
        "-  Built for large tabular time-series\n",
        "-  Extremely fast\n",
        "-  Handles non-linearity + interactions\n",
        "-  Kaggle favorite for this dataset\n",
        "-  Best balance of accuracy + speed"
      ],
      "metadata": {
        "id": "TG8hxq8PMr8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Library\n",
        "!pip install -q lightgbm\n",
        "\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "9YdmY8ySMIIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare LightGBM Dataset\n",
        "lgb_train = lgb.Dataset(\n",
        "    X_train,\n",
        "    label=y_train,\n",
        "    categorical_feature=CAT_COLS,\n",
        "    free_raw_data=False\n",
        ")\n",
        "lgb_valid = lgb.Dataset(\n",
        "    X_valid,\n",
        "    label=y_valid,\n",
        "    reference=lgb_train,\n",
        "    categorical_feature=CAT_COLS,\n",
        "    free_raw_data=False\n",
        ")"
      ],
      "metadata": {
        "id": "NYxce_j5NFqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_params = {\n",
        "    \"objective\": \"regression\",\n",
        "    \"metric\": \"rmse\",\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 64,\n",
        "    \"max_depth\": -1,\n",
        "    \"feature_fraction\": 0.8,\n",
        "    \"bagging_fraction\": 0.8,\n",
        "    \"bagging_freq\":5,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"seed\": 42,\n",
        "    \"lambda_l1\": 0.1,\n",
        "    \"lambda_l2\": 0.1,\n",
        "    \"verbosity\": -1,\n",
        "    \"boosting_type\": \"gbdt\"\n",
        "}"
      ],
      "metadata": {
        "id": "Yqhfm9xXN3NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = lgb.train(\n",
        "    params=lgb_params,\n",
        "    train_set=lgb_train,\n",
        "    num_boost_round=1000,\n",
        "    valid_sets=[lgb_train, lgb_valid],\n",
        "    valid_names=[\"train\", \"valid\"],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        ")"
      ],
      "metadata": {
        "id": "746uxc2aN4jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Prediction\n",
        "lgb_valid_pred = lgb_model.predict(\n",
        "    X_valid,\n",
        "    num_iteration=lgb_model.best_iteration\n",
        ")\n",
        "lgb_rmsle = rmsle(y_valid, lgb_valid_pred)\n",
        "print(f\"LightGBM RMSLE: {lgb_rmsle:.4f}\")"
      ],
      "metadata": {
        "id": "4Rnz0oOsQCKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "lgb_importance = pd.DataFrame({\n",
        "    \"feature\": X_train.columns,\n",
        "    \"importance\": lgb_model.feature_importance()\n",
        "}).sort_values(by=\"importance\", ascending=False)"
      ],
      "metadata": {
        "id": "sWYDcv4pRJ6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot top 20 Features\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.barh(\n",
        "    lgb_importance[\"feature\"][:20][::-1],\n",
        "    lgb_importance[\"importance\"][:20][::-1]\n",
        ")\n",
        "plt.title(\"LightGBM Feature Importance (Top 20)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8Rgv2_2pRJx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Feature Importance\n",
        "lgb_importance.to_csv(\"lgb_feature_importance.csv\", index=False)"
      ],
      "metadata": {
        "id": "J3mSglokQVle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save LightBGM\n",
        "lgb_model.save_model(\"models/baseline_lightgbm.txt\")"
      ],
      "metadata": {
        "id": "768ZYRGgP2-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 4 - CatBoost (practical view)\n",
        "\n",
        " - Strong with categorical features\n",
        " - Handles non-linearity well\n",
        " - Stable training, less tuning required"
      ],
      "metadata": {
        "id": "CPitawEySXyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library\n",
        "!pip install -q catboost\n",
        "\n",
        "from catboost import CatBoostRegressor"
      ],
      "metadata": {
        "id": "otMDqEkuSV_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CatBoost Model\n",
        "cat_model = CatBoostRegressor(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.05,\n",
        "    depth=8,\n",
        "    loss_function=\"RMSE\",\n",
        "    eval_metric=\"RMSE\",\n",
        "    random_seed=42,\n",
        "    bagging_temperature=0.2,\n",
        "    verbose=100,\n",
        "    early_stopping_rounds=50\n",
        ")"
      ],
      "metadata": {
        "id": "e6LKnByuTMId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model.fit(\n",
        "    X_train, y_train,\n",
        "    cat_features=CAT_COLS,\n",
        "    eval_set=(X_valid, y_valid),\n",
        "    use_best_model=True\n",
        ")"
      ],
      "metadata": {
        "id": "7wnC_AeoTL2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Prediction\n",
        "cat_valid_pred = cat_model.predict(X_valid)\n",
        "cat_rmsle = rmsle(y_valid, cat_valid_pred)\n",
        "\n",
        "print(f\"CatBoost RMSLE: {cat_rmsle:.4f}\")"
      ],
      "metadata": {
        "id": "p4Ab9TtkTLSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfitting Check\n",
        "cat_train_pred = cat_model.predict(X_train)\n",
        "train_rmsle = rmsle(y_train, cat_train_pred)\n",
        "valid_rmsle = cat_rmsle\n",
        "\n",
        "print(f\"Train RMSLE: {train_rmsle:.4f}\")\n",
        "print(f\"Validation RMSLE: {valid_rmsle:.4f}\")"
      ],
      "metadata": {
        "id": "EYnUggEFRJoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save CatBoost\n",
        "cat_model.save_model(\"models/catboost.cbm\", format=\"cbm\")"
      ],
      "metadata": {
        "id": "Gxw7W60aP8Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Comparision\n",
        "Compare Model Based on RMSLE"
      ],
      "metadata": {
        "id": "pBmyQdpJV3FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Comparision\n",
        "model_rmsle = pd.DataFrame({\n",
        "    \"Model\": [\"Random Forest\", \"XGBoost\", \"LightGBM\", \"CatBoost\"],\n",
        "    \"RMSLE\": [rf_rmsle, xgb_rmsle, lgb_rmsle, cat_rmsle]\n",
        "}).sort_values(by=\"RMSLE\", ascending=True)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=\"Model\", y=\"RMSLE\", data=model_rmsle)\n",
        "plt.title(\"Model RMSLE Comparison\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"RMSLE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XqtuHnsHRJe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning with Optuna (LightGBM)\n",
        "\n",
        "### Key Principles\n",
        "\n",
        " - Tune only LightGBM\n",
        " - Use time-based validation\n",
        " - Optimize RMSLE\n",
        " - Keep trials controlled"
      ],
      "metadata": {
        "id": "yUoqWqDOXA7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "metadata": {
        "id": "pIFpfNXyYPlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  params = {\n",
        "    \"objective\": \"regression\",\n",
        "    \"metric\": \"rmse\",\n",
        "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
        "    \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 256),\n",
        "    \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
        "    \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
        "    \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
        "    \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
        "    \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 5.0),\n",
        "    \"verbosity\": -1,\n",
        "    \"seed\": 42\n",
        "  }\n",
        "  model = lgb.train(\n",
        "    params=params,\n",
        "    train_set=lgb_train,\n",
        "    num_boost_round=1000,\n",
        "    valid_sets=[lgb_valid],\n",
        "    callbacks=[\n",
        "      lgb.early_stopping(stopping_rounds=50),\n",
        "      lgb.log_evaluation(period=0)  # period=0 disables logging\n",
        "    ]\n",
        "  )\n",
        "  preds = model.predict(\n",
        "    X_valid,\n",
        "    num_iteration=model.best_iteration\n",
        "  )\n",
        "  return rmsle(y_valid, preds)"
      ],
      "metadata": {
        "id": "EiEFOjtmRJWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Optuna Study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(\n",
        "  objective,\n",
        "  n_trials=50,\n",
        "  show_progress_bar=True\n",
        ")"
      ],
      "metadata": {
        "id": "fXoUYL_bRJOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain Best Parameter and score\n",
        "print('Best RMSLE', study.best_value)\n",
        "print('Best Parameters:')\n",
        "for key, value in study.best_params.items():\n",
        "  print(f'{key}: {value}')"
      ],
      "metadata": {
        "id": "tvPEv7WiRJF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain Fine Tuned LighGBM\n",
        "best_params = study.best_params\n",
        "best_params.update(\n",
        "    {\n",
        "        \"objective\": \"regression\",\n",
        "        \"metric\": \"rmse\",\n",
        "        \"verbosity\": -1,\n",
        "        \"seed\": 42\n",
        "    }\n",
        ")\n",
        "\n",
        "final_lgb_model = lgb.train(\n",
        "    params=best_params,\n",
        "    train_set=lgb_train,\n",
        "    num_boost_round=2000,\n",
        "    valid_sets=[lgb_valid],\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=50),\n",
        "        lgb.log_evaluation(period=100)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "J-K7upsqRInb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Evaluation\n",
        "final_preds = final_lgb_model.predict(\n",
        "    X_valid,\n",
        "    num_iteration=final_lgb_model.best_iteration\n",
        ")\n",
        "final_rmsle = rmsle(y_valid, final_preds)\n",
        "\n",
        "print(f\"Final Tuned LightGBM RMSLE: {final_rmsle:.4f}\")"
      ],
      "metadata": {
        "id": "cGGbKQD3bYpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save LightBGM\n",
        "final_lgb_model.save_model(\"models/tuned_lightgbm.txt\")"
      ],
      "metadata": {
        "id": "bKq-WG82TKMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare all Models"
      ],
      "metadata": {
        "id": "gyZV7GTxcBbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare all Modles\n",
        "final_results = pd.DataFrame({\n",
        "    \"Model\": [\n",
        "        \"Random Forest\",\n",
        "        \"XGBoost\",\n",
        "        \"CatBoost\",\n",
        "        \"LightGBM (Baseline)\",\n",
        "        \"LightGBM (Tuned)\"\n",
        "    ],\n",
        "    \"RMSLE\": [\n",
        "        rf_rmsle,\n",
        "        xgb_rmsle,\n",
        "        cat_rmsle,\n",
        "        lgb_rmsle,\n",
        "        final_rmsle\n",
        "    ]\n",
        "}).sort_values(\"RMSLE\")\n",
        "\n",
        "final_results\n"
      ],
      "metadata": {
        "id": "Waec2qDIcAyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Final Report"
      ],
      "metadata": {
        "id": "EWxlNuj1BZXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Models Report\n",
        "final_results.to_csv(\n",
        "    \"data/reports/ml_model_comparison_reports.csv\",\n",
        "    index=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "wOaUsDYpCN7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}