{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on Test Set"
      ],
      "metadata": {
        "id": "WxYN3dTNBr5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone GitHub Repository\n",
        "!git clone https://github.com/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform.git"
      ],
      "metadata": {
        "id": "mgzpKyEt0cIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q catboost\n",
        "!pip install category_encoders\n"
      ],
      "metadata": {
        "id": "quKqcXebzW8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Test Data"
      ],
      "metadata": {
        "id": "XR7epSqlCYnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Environment Setup - Import Libraries\n",
        "import os\n",
        "import gc\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "QtTyGleN00kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Project Root\n",
        "os.chdir(\"/content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform\")\n",
        "print(\"Current Directory: \", os.getcwd())"
      ],
      "metadata": {
        "id": "BTOWtTAk1Cyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Feature-Engineered Data\n",
        "DATA_DIR = Path(\"data/features\")\n",
        "\n",
        "train = pd.read_parquet(DATA_DIR / \"train_features.parquet\")\n",
        "test  = pd.read_parquet(DATA_DIR / \"test_features.parquet\")\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape :\", test.shape)\n",
        "\n",
        "# Sort for time-series\n",
        "train = train.sort_values([\"store_nbr\", \"family\", \"date\"]).reset_index(drop=True)\n",
        "test  = test.sort_values([\"store_nbr\", \"family\", \"date\"]).reset_index(drop=True)\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "fa1Hvx161Hbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load All Saved Models and Artifacts\n",
        "\n",
        "# Random Forest\n",
        "rf_model = joblib.load(\"models/random_forest/random_forest.pkl\")\n",
        "\n",
        "# Target Encoder\n",
        "target_encoder = joblib.load(\"models/random_forest/target_encoder.pkl\")\n",
        "\n",
        "# CatBoost\n",
        "cat_model = CatBoostRegressor()\n",
        "cat_model.load_model(\"models/catboost/catboost.cbm\")\n",
        "\n",
        "# LightGBM\n",
        "lgb_model = lgb.Booster(model_file=\"models/lightgbm/baseline_lightgbm.txt\")\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = xgb.Booster()\n",
        "xgb_model.load_model(\"models/xgboost/xgboost.json\")"
      ],
      "metadata": {
        "id": "ERqxs9fwhDA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Final Ensemble Bundle\n",
        "bundle = joblib.load(\"models/ensemble-stacking/final_ensemble_model.pkl\")\n",
        "\n",
        "print(\"Loaded Ensemble Bundle Keys: \")\n",
        "for key in bundle.keys():\n",
        "  print( \" -\", key)"
      ],
      "metadata": {
        "id": "hmYF-v_IhC6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory Optimization (reduce memory usage)\n",
        "def reduce_mem_usage(df, ):\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == \"float64\":\n",
        "      df[col] = df[col].astype(\"float32\")\n",
        "    elif df[col].dtype == \"int64\":\n",
        "      df[col] = df[col].astype(\"int32\")\n",
        "  return df\n",
        "\n",
        "train = reduce_mem_usage(train)\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "0OCyRjwu2veA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Unified History Store\n",
        "history_df = train[\n",
        "    [\"store_nbr\", \"family\", \"date\", \"sales\", \"onpromotion\", \"dcoilwtico\"]\n",
        "].copy()\n",
        "\n",
        "history_df = history_df.sort_values(\n",
        "    [\"store_nbr\", \"family\", \"date\"]\n",
        ").reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "IbjXlAz9GAgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sales Lag / Roll Features\n",
        "def generate_sales_features(history, current_rows, lags, rolls):\n",
        "    for lag in lags:\n",
        "        current_rows[f\"sales_lag_{lag}\"] = (\n",
        "            history.groupby([\"store_nbr\", \"family\"])[\"sales\"]\n",
        "            .shift(lag)\n",
        "            .reindex(current_rows.index)\n",
        "        )\n",
        "\n",
        "    for r in rolls:\n",
        "        roll = (\n",
        "            history.groupby([\"store_nbr\", \"family\"])[\"sales\"]\n",
        "            .rolling(r)\n",
        "            .agg([\"mean\", \"std\"])\n",
        "            .reset_index(level=[0,1], drop=True)\n",
        "        )\n",
        "        current_rows[f\"sales_roll_mean_{r}\"] = roll[\"mean\"].reindex(current_rows.index)\n",
        "        current_rows[f\"sales_roll_std_{r}\"]  = roll[\"std\"].reindex(current_rows.index)\n",
        "\n",
        "    return current_rows\n"
      ],
      "metadata": {
        "id": "OA7hu3cGGgc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Promo Features\n",
        "def generate_promo_features(history, current_rows, lags, rolls):\n",
        "    for lag in lags:\n",
        "        current_rows[f\"promo_lag_{lag}\"] = (\n",
        "            history.groupby([\"store_nbr\", \"family\"])[\"onpromotion\"]\n",
        "            .shift(lag)\n",
        "            .reindex(current_rows.index)\n",
        "        )\n",
        "\n",
        "    for r in rolls:\n",
        "        rolling = (\n",
        "            history.groupby([\"store_nbr\", \"family\"])[\"onpromotion\"]\n",
        "            .rolling(r)\n",
        "        )\n",
        "        current_rows[f\"promo_roll_sum_{r}\"] = rolling.sum().reset_index(level=[0,1], drop=True)\n",
        "        current_rows[f\"promo_freq_{r}\"] = (\n",
        "            rolling.mean().reset_index(level=[0,1], drop=True)\n",
        "        )\n",
        "\n",
        "    current_rows[\"promo_flag\"] = (current_rows[\"onpromotion\"] > 0).astype(int)\n",
        "\n",
        "    return current_rows\n"
      ],
      "metadata": {
        "id": "kELcz5WKHBWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oil Lag Features\n",
        "def generate_oil_features(history, current_rows, lags):\n",
        "    for lag in lags:\n",
        "        current_rows[f\"oil_lag_{lag}\"] = (\n",
        "            history.groupby(\"store_nbr\")[\"dcoilwtico\"]\n",
        "            .shift(lag)\n",
        "            .reindex(current_rows.index)\n",
        "        )\n",
        "    return current_rows\n"
      ],
      "metadata": {
        "id": "SB89tMnSHIWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursive Test Feature Generation Loop\n",
        "LAGS  = [1, 7, 14, 28]\n",
        "ROLLS = [7, 14, 28]\n",
        "\n",
        "test_preds = []\n",
        "\n",
        "for current_date in sorted(test[\"date\"].unique()):\n",
        "\n",
        "    # 1️⃣ Select current day rows\n",
        "    test_day = test[test[\"date\"] == current_date].copy()\n",
        "\n",
        "    # 2️⃣ Append placeholder sales (NaN)\n",
        "    test_day[\"sales\"] = np.nan\n",
        "\n",
        "    # 3️⃣ Temporarily append to history\n",
        "    temp_history = pd.concat([history_df, test_day], ignore_index=True)\n",
        "\n",
        "    # 4️⃣ Generate features\n",
        "    test_day = generate_sales_features(temp_history, test_day, LAGS, ROLLS)\n",
        "    test_day = generate_promo_features(temp_history, test_day, [1,7], ROLLS)\n",
        "    test_day = generate_oil_features(temp_history, test_day, [7,14,28])\n",
        "\n",
        "    # 5️⃣ Drop rows where lags not ready\n",
        "    test_day = test_day.dropna(subset=[f\"sales_lag_{l}\" for l in LAGS])\n",
        "\n",
        "    # 6️⃣ Store for inference\n",
        "    test_preds.append(test_day)\n"
      ],
      "metadata": {
        "id": "35ru3PTfHRdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Test Features\n",
        "test_feature_full = pd.concat(test_preds).reset_index(drop=True)\n",
        "test_feature_full = reduce_mem_usage(test_feature_full)\n",
        "\n",
        "print(\"Test Feature Shape: \", test_feature_full.shape)"
      ],
      "metadata": {
        "id": "_gQh_299H_Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Unneceaary Columns in Test Set\n",
        "DROP_COLS = [\"id\", \"date\", \"sales\", \"sales_log\"]\n",
        "\n",
        "TRAIN_FEATURES = [\n",
        "    col for col in train.columns\n",
        "    if col not in DROP_COLS\n",
        "]\n",
        "\n",
        "# Drop Forbidden Columns\n",
        "test_feature_full = test_feature_full.drop(\n",
        "    columns=[c for c in [\"sales\", \"sales_log\"] if c in test_feature_full],\n",
        "    errors=\"ignore\"\n",
        ")\n",
        "\n",
        "test_features_full = test_feature_full[TRAIN_FEATURES]\n",
        "\n",
        "\n",
        "print(f\"Total train features: {len(TRAIN_FEATURES)}\")\n"
      ],
      "metadata": {
        "id": "A04y76BeIuav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert test_features_full.shape[1] == len(TRAIN_FEATURES)\n",
        "assert test_features_full.isnull().sum().sum() == 0\n",
        "\n",
        "print(\"Feature validation PASSED\")\n",
        "print(\"Test shape:\", test_features_full.shape)\n"
      ],
      "metadata": {
        "id": "rrNY2LeDJnws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Inputs\n",
        "X_test_te = bundle[\"target_encoder\"].transform(test_features_full)\n",
        "X_test_raw = test_features_full.copy()"
      ],
      "metadata": {
        "id": "IBJYgzRAKWzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Prediction Function\n",
        "\n",
        "def predict_from_bundle(X_raw, bundle):\n",
        "    \"\"\"\n",
        "    X_raw : DataFrame with EXACT training features\n",
        "    returns : sales predictions (original scale)\n",
        "    \"\"\"\n",
        "\n",
        "    # Target encoding (RF + XGB)\n",
        "    X_te = bundle[\"target_encoder\"].transform(X_raw)\n",
        "\n",
        "    # Base model predictions (LOG scale)\n",
        "    preds = np.column_stack([\n",
        "        bundle[\"rf_model\"].predict(X_te),\n",
        "        bundle[\"xgb_model\"].predict(xgb.DMatrix(X_te)),\n",
        "        bundle[\"lgb_model\"].predict(\n",
        "            X_raw,\n",
        "            num_iteration=bundle[\"lgb_model\"].best_iteration\n",
        "        ),\n",
        "        bundle[\"cat_model\"].predict(X_raw),\n",
        "    ])\n",
        "\n",
        "    # Meta-model (stacking)\n",
        "    y_log = bundle[\"meta_model\"].predict(preds)\n",
        "\n",
        "    # Bias correction\n",
        "    y_log += bundle[\"bias\"]\n",
        "\n",
        "    # Zero-sales handling\n",
        "    y_log = np.where(y_log < bundle[\"zero_threshold\"], 0, y_log)\n",
        "\n",
        "    # Back to original scale\n",
        "    return np.expm1(y_log)\n"
      ],
      "metadata": {
        "id": "hFaIZonJOL5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on Test Set\n",
        "test[\"sales_pred\"] = predict_from_bundle(\n",
        "    test_features_full,\n",
        "    bundle\n",
        ")\n",
        "\n",
        "test[[\"date\", \"store_nbr\", \"family\", \"sales_pred\"]].head()\n"
      ],
      "metadata": {
        "id": "D7FNIYJsOg5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Test Forecast Trend\n",
        "daily_forecast = (\n",
        "    test.groupby(\"date\")[\"sales_pred\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(daily_forecast[\"date\"], daily_forecast[\"sales_pred\"])\n",
        "plt.title(\"Test Forecast Trend (Total Sales)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Predicted Sales\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4s-n3JB3OjE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store-wise Forecast Plot\n",
        "sample_store = test[\"store_nbr\"].iloc[0]\n",
        "\n",
        "store_forecast = test[test[\"store_nbr\"] == sample_store]\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(store_forecast[\"date\"], store_forecast[\"sales_pred\"])\n",
        "plt.title(f\"Store {sample_store} – Forecast Trend\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Predicted Sales\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d5CjtVqbO1Ge"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}