{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxYN3dTNBr5M"
      },
      "source": [
        "# Prediction on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgzpKyEt0cIc"
      },
      "source": [
        "# Clone GitHub Repository\n",
        "!git clone https://github.com/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quKqcXebzW8q"
      },
      "source": [
        "!pip install -q catboost\n",
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR7epSqlCYnX"
      },
      "source": [
        "## Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtTyGleN00kX"
      },
      "source": [
        "# Environment Setup - Import Libraries\n",
        "import os\n",
        "import gc\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTOWtTAk1Cyx"
      },
      "source": [
        "# Set Project Root\n",
        "os.chdir(\"/content/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform\")\n",
        "print(\"Current Directory: \", os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa1Hvx161Hbc"
      },
      "source": [
        "# Load Feature-Engineered Data\n",
        "DATA_DIR = Path(\"data/features\")\n",
        "\n",
        "train = pd.read_parquet(DATA_DIR / \"train_features.parquet\")\n",
        "test  = pd.read_parquet(DATA_DIR / \"test_features.parquet\")\n",
        "\n",
        "train = train.sort_values([\"store_nbr\", \"family\", \"date\"]).reset_index(drop=True)\n",
        "test  = test.sort_values([\"store_nbr\", \"family\", \"date\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape :\", test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIYcB3NKbaUR"
      },
      "source": [
        "# Load All Model and Ensemble Bundle\n",
        "bundle = joblib.load(\"models/ensemble-stacking/final_ensemble_model.pkl\")\n",
        "\n",
        "print(\"Loaded Ensemble Components:\")\n",
        "for k in bundle:\n",
        "    print(\" -\", k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO9Qgf3dakoi"
      },
      "source": [
        "# Memory Optimization\n",
        "def reduce_mem_usage(df):\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == \"float64\":\n",
        "            df[col] = df[col].astype(\"float32\")\n",
        "        elif df[col].dtype == \"int64\":\n",
        "            df[col] = df[col].astype(\"int32\")\n",
        "    return df\n",
        "\n",
        "train = reduce_mem_usage(train)\n",
        "test  = reduce_mem_usage(test)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGzv2z94aq_I"
      },
      "source": [
        "# Define Lag / Rolls\n",
        "LAGS  = [1, 7, 14, 28]\n",
        "ROLLS = [7, 14, 28]\n",
        "MAX_LAG = max(LAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg1BcsLkawUD"
      },
      "source": [
        "# Build Initial History Store\n",
        "history_df = train[\n",
        "    train[\"date\"] >= (train[\"date\"].max() - pd.Timedelta(days=MAX_LAG + 30))\n",
        "][[\"store_nbr\", \"family\", \"date\", \"sales\", \"onpromotion\", \"dcoilwtico\"]].copy()\n",
        "\n",
        "history_df = history_df.sort_values(\n",
        "    [\"store_nbr\", \"family\", \"date\"]\n",
        ").reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALNWijWya3Xs"
      },
      "source": [
        "# Define Feature Generator\n",
        "def generate_sales_features(history, current, lags, rolls):\n",
        "    for lag in lags:\n",
        "        current[f\"sales_lag_{lag}\"] = (\n",
        "            history.groupby([\"store_nbr\",\"family\"])[\"sales\"]\n",
        "            .shift(lag)\n",
        "            .reindex(current.index)\n",
        "        )\n",
        "    for r in rolls:\n",
        "        roll = (\n",
        "            history.groupby([\"store_nbr\",\"family\"])[\"sales\"]\n",
        "            .rolling(r)\n",
        "            .agg([\"mean\",\"std\"])\n",
        "            .reset_index(level=[0,1], drop=True)\n",
        "        )\n",
        "        current[f\"sales_roll_mean_{r}\"] = roll[\"mean\"].reindex(current.index)\n",
        "        current[f\"sales_roll_std_{r}\"]  = roll[\"std\"].reindex(current.index)\n",
        "    return current\n",
        "\n",
        "\n",
        "def generate_promo_features(history, current, lags, rolls):\n",
        "    for lag in lags:\n",
        "        current[f\"promo_lag_{lag}\"] = (\n",
        "            history.groupby([\"store_nbr\",\"family\"])[\"onpromotion\"]\n",
        "            .shift(lag)\n",
        "            .reindex(current.index)\n",
        "        )\n",
        "    for r in rolls:\n",
        "        rolling = history.groupby([\"store_nbr\",\"family\"])[\"onpromotion\"].rolling(r)\n",
        "        current[f\"promo_roll_sum_{r}\"] = rolling.sum().reset_index(level=[0,1], drop=True)\n",
        "        current[f\"promo_freq_{r}\"] = rolling.mean().reset_index(level=[0,1], drop=True)\n",
        "    current[\"promo_flag\"] = (current[\"onpromotion\"] > 0).astype(int)\n",
        "    return current\n",
        "\n",
        "\n",
        "def generate_oil_features(history, current, lags):\n",
        "    for lag in lags:\n",
        "        current[f\"oil_lag_{lag}\"] = (\n",
        "            history.groupby(\"store_nbr\")[\"dcoilwtico\"]\n",
        "            .shift(lag)\n",
        "            .reindex(current.index)\n",
        "        )\n",
        "    return current"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__EEDloga8qV"
      },
      "source": [
        "# Training Feature List\n",
        "DROP_COLS = [\"id\", \"date\", \"sales\", \"sales_log\"]\n",
        "TRAIN_FEATURES = [c for c in train.columns if c not in DROP_COLS]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rRg2XohbFFu"
      },
      "source": [
        "# Final Prediction Function\n",
        "def predict_from_bundle(X_raw, bundle):\n",
        "\n",
        "    X_te = bundle[\"target_encoder\"].transform(X_raw)\n",
        "\n",
        "    preds = np.column_stack([\n",
        "        bundle[\"rf_model\"].predict(X_te),\n",
        "        bundle[\"xgb_model\"].predict(xgb.DMatrix(X_te)),\n",
        "        bundle[\"lgb_model\"].predict(X_raw, num_iteration=bundle[\"lgb_model\"].best_iteration),\n",
        "        bundle[\"cat_model\"].predict(X_raw),\n",
        "    ])\n",
        "\n",
        "    y_log = bundle[\"meta_model\"].predict(preds)\n",
        "    y_log += bundle[\"bias\"]\n",
        "    y_log = np.where(y_log < bundle[\"zero_threshold\"], 0, y_log)\n",
        "\n",
        "    return np.expm1(y_log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWi9jX7xbKzV"
      },
      "source": [
        "# Recursive Test Prediction Loop\n",
        "test_preds = []\n",
        "test_dates = sorted(test[\"date\"].unique())\n",
        "\n",
        "for current_date in test_dates:\n",
        "\n",
        "    test_day = test[test[\"date\"] == current_date].copy()\n",
        "\n",
        "    temp_history = pd.concat([history_df, test_day], ignore_index=True)\n",
        "\n",
        "    test_day = generate_sales_features(temp_history, test_day, LAGS, ROLLS)\n",
        "    test_day = generate_promo_features(temp_history, test_day, [1,7], ROLLS)\n",
        "    test_day = generate_oil_features(temp_history, test_day, [7,14,28])\n",
        "\n",
        "    # Safe filling\n",
        "    sales_cols = [c for c in test_day if \"sales_\" in c]\n",
        "    test_day[sales_cols] = test_day[sales_cols].fillna(0)\n",
        "    test_day = test_day.ffill().bfill()\n",
        "\n",
        "    # Predict\n",
        "    test_day[\"sales\"] = predict_from_bundle(\n",
        "        test_day[TRAIN_FEATURES], bundle\n",
        "    )\n",
        "\n",
        "    # Update history with predictions\n",
        "    history_df = pd.concat([history_df, test_day], ignore_index=True)\n",
        "\n",
        "    test_preds.append(test_day)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvTKpcYMbq2Y"
      },
      "source": [
        "# Final Test Prediction\n",
        "test_final = pd.concat(test_preds).reset_index(drop=True)\n",
        "test_final[\"sales_pred\"] = test_final[\"sales\"]\n",
        "\n",
        "print(\"Final Test Shape:\", test_final.shape)\n",
        "test_final[[\"date\",\"store_nbr\",\"family\",\"sales_pred\"]].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s-n3JB3OjE4",
        "collapsed": true
      },
      "source": [
        "# Plot Test Forecast Trend\n",
        "daily_forecast = test_final.groupby(\"date\")[\"sales_pred\"].sum().reset_index()\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(daily_forecast[\"date\"], daily_forecast[\"sales_pred\"])\n",
        "plt.title(\"Test Forecast Trend (Total Sales)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Predicted Sales\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store-wise Forecast Plot\n",
        "sample_store = test_final[\"store_nbr\"].iloc[0]\n",
        "\n",
        "store_forecast = test_final[test_final[\"store_nbr\"] == sample_store]\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(store_forecast[\"date\"], store_forecast[\"sales_pred\"])\n",
        "plt.title(f\"Store {sample_store} – Forecast Trend\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Predicted Sales\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KEeRivE9ZbEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle submission format\n",
        "submission = (\n",
        "    test_final[[\"id\", \"sales_pred\"]]\n",
        "    .rename(columns={\"sales_pred\": \"sales\"})\n",
        "    .copy()\n",
        ")\n",
        "\n",
        "submission[\"sales\"] = submission[\"sales\"].clip(lower=0)\n",
        "\n",
        "print(submission.head())\n",
        "print(\"Submission shape:\", submission.shape)\n"
      ],
      "metadata": {
        "id": "21JT4OBnU87I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Submission\n",
        "submission_path = \"outputs/kaggle_submission.csv\"\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "submission.to_csv(submission_path, index=False)\n",
        "print(f\"Saved Kaggle submission → {submission_path}\")\n"
      ],
      "metadata": {
        "id": "EwXxmiQDVHkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Full Forecast\n",
        "forecast_cols = [\n",
        "    \"date\",\n",
        "    \"store_nbr\",\n",
        "    \"family\",\n",
        "    \"sales_pred\"\n",
        "]\n",
        "\n",
        "forecast_df = test_final[forecast_cols].copy()\n",
        "forecast_path = \"outputs/forecast.parquet\"\n",
        "\n",
        "# to_csv\n",
        "forecast_df.to_csv(\n",
        "    \"outputs/test_forecast_full.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "# to_parquet\n",
        "forecast_df.to_parquet(\n",
        "    \"outputs/test_forecast_full.parquet\",\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "id": "8k7SDcdFVUaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}