# ğŸ“¦ Enterprise Intelligent Demand Forecasting & Decision Optimization Platform

An endâ€‘toâ€‘end **enterpriseâ€‘grade demand forecasting system** designed to predict daily sales at scale using **Machine Learning, Deep Learning, and Time Series modeling**, followed by **decisionâ€‘oriented optimization** for business use cases such as inventory planning and operations.

This project is inspired by realâ€‘world retail forecasting challenges and is structured to reflect **productionâ€‘ready ML pipelines** used in industry.

---

## ğŸš€ Project Objectives

- Forecast **daily productâ€‘level demand** across multiple stores
- Incorporate **promotions, holidays, oil prices, and seasonality**
- Compare **baseline, ML, and DL models** systematically
- Build a **robust inference pipeline** for unseen test data
- Enable **decision optimization** using forecast outputs
- Follow **enterprise ML best practices** (modularity, reproducibility, scalability)

---

## ğŸ§  Key Features

âœ… Endâ€‘toâ€‘end forecasting pipeline (train â†’ validate â†’ test â†’ inference)  
âœ… Rich **timeâ€‘series feature engineering** (lags, rolling stats, calendars)  
âœ… Multiple model families:
- Statistical baselines
- Classical ML (Treeâ€‘based)
- Deep Learning (LSTM / GRU)

âœ… Logâ€‘scale training with **RMSLE optimization**  
âœ… Prediction interval estimation  
âœ… Model artifact versioning (scalers, encoders, models)  
âœ… Kaggleâ€‘ready submission generation  

---

## ğŸ—ï¸ Project Architecture

```
Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform/
â”‚
â”œâ”€â”€ app/                    # Core pipeline scripts
â”‚   â”œâ”€â”€ train.py            # Model training entry point
â”‚   â”œâ”€â”€ inference.py        # Test / production inference
â”‚   â””â”€â”€ evaluate.py         # Model evaluation
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original datasets
â”‚   â”œâ”€â”€ processed/          # Cleaned & featureâ€‘engineered data
â”‚   â””â”€â”€ external/           # Holidays, oil prices, metadata
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks (stepâ€‘byâ€‘step development)
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_baselines.ipynb
â”‚   â”œâ”€â”€ 04_ml_models.ipynb
â”‚   â”œâ”€â”€ 05_deep_learning.ipynb
â”‚   â”œâ”€â”€ 06_ensembling.ipynb
â”‚   â””â”€â”€ 07_inference_pipeline.ipynb
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baselines/
â”‚   â”œâ”€â”€ ml_models/
â”‚   â””â”€â”€ deep_learning/
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ predictions/        # CSV / Parquet outputs
â”‚   â”œâ”€â”€ submission/         # Kaggle submission files
â”‚   â””â”€â”€ evaluation/         # Metrics & plots
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_utils.py       # Data loading & cleaning
â”‚   â”œâ”€â”€ feature_utils.py    # Feature engineering helpers
â”‚   â”œâ”€â”€ model_utils.py      # Training & saving models
â”‚   â””â”€â”€ metrics.py          # Evaluation metrics
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml         # Centralized configuration
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š Data Description

The dataset consists of **daily sales records** with the following dimensions:

- **Store ID**
- **Product family**
- **Date**
- **Sales volume**
- **Promotions (onpromotion)**
- **Holidays & events**
- **Oil prices**

ğŸ“Œ Target Variable:
- `sales` (modeled using `log1p(sales)` for stability)

---

## ğŸ§ª Feature Engineering

- Lag features: `sales_lag_1`, `sales_lag_7`, `sales_lag_14`, `sales_lag_28`
- Rolling statistics:
  - 7 / 14 / 28 day mean
  - Rolling std
- Calendar features:
  - Day of week
  - Week of year
  - Month
  - Is weekend
- Eventâ€‘based features:
  - Holiday indicators
  - Promotion flags

---

## ğŸ¤– Models Implemented

### 1ï¸âƒ£ Baseline Models

- Naive (Last value)
- Moving Average (7 / 14 / 28 days)

### 2ï¸âƒ£ Machine Learning Models

- LightGBM
- XGBoost
- CatBoost

### 3ï¸âƒ£ Deep Learning Models

- LSTM (Sliding window approach)
- GRU

ğŸ“Œ All DL models are trained on **logâ€‘scaled targets** and evaluated using RMSLE.

---

## ğŸ“ Evaluation Metrics

- **RMSLE** (Primary)
- MAE
- Storeâ€‘level error analysis
- Productâ€‘level error analysis

---

## ğŸ“¤ Inference & Submission

The inference pipeline:

- Loads trained models & preprocessing artifacts
- Generates predictions for unseen test data
- Applies inverse log transformation
- Clips negative values
- Saves outputs as:
  - CSV
  - Parquet
- Produces **Kaggleâ€‘ready submission files**

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/sabin74/Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform.git
cd Enterprise-Intelligent-Demand-Forecasting-Decision-Optimization-Platform
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Run

### Train Models
```bash
python app/train.py
```

### Run Inference
```bash
python app/inference.py
```

---

## ğŸ§© Decision Optimization (Planned / Extension)

- Safety stock calculation
- Reorder point estimation
- Promotion sensitivity analysis
- Demandâ€‘driven inventory recommendations

---

## ğŸ§  Skills Demonstrated

- Time Series Forecasting
- Feature Engineering at Scale
- ML & Deep Learning Model Design
- Pipeline Engineering
- Model Evaluation & Validation
- Productionâ€‘style Inference Design

---

## ğŸ”® Future Improvements

- Probabilistic forecasting (Quantile loss)
- Model stacking & weighted ensembling
- SHAPâ€‘based explainability
- API deployment (FastAPI)
- Realâ€‘time forecasting support

---

## ğŸ‘¤ Author

**Sabin Lamsal**  
Machine Learning & Data Science Enthusiast  
Focused on building scalable, realâ€‘world AI systems

---

â­ If you find this project useful, consider giving it a star!

